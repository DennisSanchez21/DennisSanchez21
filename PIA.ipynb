{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpRFB2AoBpyw2LPhVqu4PB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DennisSanchez21/DennisSanchez21/blob/main/PIA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkziOLMUXMML"
      },
      "outputs": [],
      "source": [
        "# Variables Personalizadas\n",
        "nombre = \"Estefany Dennis Sanchez Chavez\"\n",
        "id_estudiante = \"2010604\"\n",
        "profesor = \"Teacher: Daniel Isaías Lopez Paez\"\n",
        "horario = \"Horario: Jueves\"\n",
        "\n",
        "# Instalación y configuración de la API de Kaggle\n",
        "!pip install kaggle\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Sube el archivo kaggle.json\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Configuración de credenciales de Kaggle\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "os.rename(\"kaggle.json\", \"/root/.kaggle/kaggle.json\")\n",
        "os.chmod(\"/root/.kaggle/kaggle.json\", 600)\n",
        "\n",
        "# Descarga el dataset\n",
        "!kaggle datasets download -d uraninjo/augmented-alzheimer-mri-dataset -p /content/\n",
        "\n",
        "# Extracción del archivo .zip\n",
        "import zipfile\n",
        "zip_path = '/content/augmented-alzheimer-mri-dataset.zip'\n",
        "extract_path = '/content/augmented-alzheimer-mri-dataset/'\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Verificar archivos extraídos\n",
        "extracted_files = os.listdir(extract_path)\n",
        "print(\"Archivos extraídos:\", extracted_files)\n",
        "\n",
        "# Librerías para el modelo\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Definir la ruta del dataset\n",
        "dataset_path = \"/content/augmented-alzheimer-mri-dataset/AugmentedAlzheimerDataset\"\n",
        "\n",
        "# Preprocesamiento de datos\n",
        "img_size = 150\n",
        "batch_size = 32\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0, validation_split=0.2)\n",
        "\n",
        "train_data = datagen.flow_from_directory(\n",
        "    dataset_path, target_size=(img_size, img_size), batch_size=batch_size,\n",
        "    class_mode='categorical', subset='training'\n",
        ")\n",
        "val_data = datagen.flow_from_directory(\n",
        "    dataset_path, target_size=(img_size, img_size), batch_size=batch_size,\n",
        "    class_mode='categorical', subset='validation'\n",
        ")\n",
        "\n",
        "# Definición del modelo\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(train_data.class_indices), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compilación y entrenamiento\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, validation_data=val_data, epochs=10, verbose=1)\n",
        "\n",
        "# Guardar el modelo\n",
        "model.save(\"cnn_alzheimer_model.h5\")\n",
        "\n",
        "# Pruebas y predicciones\n",
        "test_images, test_labels = next(val_data)\n",
        "predictions = model.predict(test_images)\n",
        "class_labels = list(train_data.class_indices.keys())\n",
        "\n",
        "# Mostrar predicciones\n",
        "for i in range(10):\n",
        "    plt.figure(figsize=(2, 2))\n",
        "    plt.imshow(test_images[i])\n",
        "    plt.title(f\"True: {class_labels[np.argmax(test_labels[i])]}, Pred: {class_labels[np.argmax(predictions[i])]}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Gráfica de precisión\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title(f\"Training and Validation Accuracy\\nNombre: {nombre} | ID: {id_estudiante} | {profesor} | {horario}\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ]
}